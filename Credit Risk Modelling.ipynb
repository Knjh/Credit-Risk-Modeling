{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c4bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82dec513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "a1 = pd.read_excel(\"case_study1.xlsx\")\n",
    "a2 = pd.read_excel(\"case_study2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f9e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = a1.copy()\n",
    "df2 = a2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa06d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nulls\n",
    "df1 = df1.loc[df1['Age_Oldest_TL'] != -99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd1cc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_removed = []\n",
    "\n",
    "for i in df2.columns:\n",
    "    if df2.loc[df2[i] == -99999].shape[0] > 10000:\n",
    "        columns_to_be_removed .append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6cf1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns_to_be_removed, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e0e4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df2.columns:\n",
    "    df2 = df2.loc[ df2[i] != -99999 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1a8dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes, inner join so that no nulls are present\n",
    "df = pd. merge ( df1, df2, how ='inner', left_on = ['PROSPECTID'], right_on = ['PROSPECTID'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78fbaf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS\n",
      "EDUCATION\n",
      "GENDER\n",
      "last_prod_enq2\n",
      "first_prod_enq2\n",
      "Approved_Flag\n"
     ]
    }
   ],
   "source": [
    "# check how many columns are categorical\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c193f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS --- 3.578180861038862e-233\n",
      "EDUCATION --- 2.6942265249737532e-30\n",
      "GENDER --- 1.907936100186563e-05\n",
      "last_prod_enq2 --- 0.0\n",
      "first_prod_enq2 --- 7.84997610555419e-287\n"
     ]
    }
   ],
   "source": [
    "# Chi-square test\n",
    "for i in ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']:\n",
    "    chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))\n",
    "    print(i, '---', pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11dd7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF for numerical columns\n",
    "numeric_columns = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype != 'object' and i not in ['PROSPECTID','Approved_Flag']:\n",
    "        numeric_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7f36e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data = df[numeric_columns]\n",
    "total_columns = vif_data.shape[1]\n",
    "columns_to_be_kept = []\n",
    "column_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c407124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kanhaiya/anaconda3/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --- inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kanhaiya/anaconda3/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --- inf\n",
      "0 --- 11.320180023967996\n",
      "0 --- 8.363698035000336\n",
      "0 --- 6.520647877790928\n",
      "0 --- 5.149501618212625\n",
      "1 --- 2.611111040579735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kanhaiya/anaconda3/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 --- inf\n",
      "2 --- 1788.7926256209232\n",
      "2 --- 8.601028256477228\n",
      "2 --- 3.8328007921530785\n",
      "3 --- 6.0996533816467355\n",
      "3 --- 5.5813520096427585\n",
      "4 --- 1.9855843530987785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kanhaiya/anaconda3/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 --- inf\n",
      "5 --- 4.809538302819343\n",
      "6 --- 23.270628983464636\n",
      "6 --- 30.595522588100053\n",
      "6 --- 4.3843464059655854\n",
      "7 --- 3.064658415523423\n",
      "8 --- 2.898639771299251\n",
      "9 --- 4.377876915347324\n",
      "10 --- 2.2078535836958433\n",
      "11 --- 4.916914200506864\n",
      "12 --- 5.214702030064725\n",
      "13 --- 3.3861625024231476\n",
      "14 --- 7.840583309478997\n",
      "14 --- 5.255034641721438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kanhaiya/anaconda3/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 --- inf\n",
      "15 --- 7.380634506427232\n",
      "15 --- 1.4210050015175733\n",
      "16 --- 8.083255010190323\n",
      "16 --- 1.624122752404011\n",
      "17 --- 7.257811920140003\n",
      "17 --- 15.59624383268298\n",
      "17 --- 1.825857047132431\n",
      "18 --- 1.5080839450032664\n",
      "19 --- 2.172088834824577\n",
      "20 --- 2.623397553527229\n",
      "21 --- 2.2959970812106167\n",
      "22 --- 7.360578319196446\n",
      "22 --- 2.160238777310255\n",
      "23 --- 2.8686288267891467\n",
      "24 --- 6.458218003637272\n",
      "24 --- 2.8474118865638256\n",
      "25 --- 4.7531981562840855\n",
      "26 --- 16.22735475594825\n",
      "26 --- 6.424377256363877\n",
      "26 --- 8.887080381808687\n",
      "26 --- 2.3804746142952653\n",
      "27 --- 8.60951347651454\n",
      "27 --- 13.06755093547673\n",
      "27 --- 3.500040056654653\n",
      "28 --- 1.9087955874813773\n",
      "29 --- 17.006562234161628\n",
      "29 --- 10.730485153719197\n",
      "29 --- 2.3538497522950275\n",
      "30 --- 22.104855915136433\n",
      "30 --- 2.7971639638512906\n",
      "31 --- 3.424171203217697\n",
      "32 --- 10.175021454450935\n",
      "32 --- 6.408710354561301\n",
      "32 --- 1.0011511962625623\n",
      "33 --- 3.069197305397274\n",
      "34 --- 2.8091261600643724\n",
      "35 --- 20.249538381980678\n",
      "35 --- 15.864576541593774\n",
      "35 --- 1.8331649740532168\n",
      "36 --- 1.5680839909542037\n",
      "37 --- 1.9307572353811682\n",
      "38 --- 4.331265056645247\n",
      "39 --- 9.390334396150173\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,total_columns):\n",
    "    \n",
    "    vif_value = variance_inflation_factor(vif_data, column_index)\n",
    "    print (column_index,'---',vif_value)\n",
    "    \n",
    "    \n",
    "    if vif_value <= 6:\n",
    "        columns_to_be_kept.append( numeric_columns[i] )\n",
    "        column_index = column_index+1\n",
    "    \n",
    "    else:\n",
    "        vif_data = vif_data.drop([ numeric_columns[i] ] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f17bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Anova for columns_to_be_kept \n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "columns_to_be_kept_numerical = []\n",
    "\n",
    "for i in columns_to_be_kept:\n",
    "    a = list(df[i])  \n",
    "    b = list(df['Approved_Flag'])  \n",
    "    \n",
    "    group_P1 = [value for value, group in zip(a, b) if group == 'P1']\n",
    "    group_P2 = [value for value, group in zip(a, b) if group == 'P2']\n",
    "    group_P3 = [value for value, group in zip(a, b) if group == 'P3']\n",
    "    group_P4 = [value for value, group in zip(a, b) if group == 'P4']\n",
    "\n",
    "\n",
    "    f_statistic, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)\n",
    "\n",
    "    if p_value <= 0.05:\n",
    "        columns_to_be_kept_numerical.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b9c3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing all the final features\n",
    "features = columns_to_be_kept_numerical + ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']\n",
    "df = df[features + ['Approved_Flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b7a6126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoding for the categorical features\n",
    "['MARITALSTATUS', 'EDUCATION', 'GENDER' , 'last_prod_enq2' ,'first_prod_enq2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c67796aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PL', 'ConsumerLoan', 'others', 'AL', 'HL', 'CC'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MARITALSTATUS'].unique()    \n",
    "df['EDUCATION'].unique()\n",
    "df['GENDER'].unique()\n",
    "df['last_prod_enq2'].unique()\n",
    "df['first_prod_enq2'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cec4c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['EDUCATION'] == 'SSC',['EDUCATION']]              = 1\n",
    "df.loc[df['EDUCATION'] == '12TH',['EDUCATION']]             = 2\n",
    "df.loc[df['EDUCATION'] == 'GRADUATE',['EDUCATION']]         = 3\n",
    "df.loc[df['EDUCATION'] == 'UNDER GRADUATE',['EDUCATION']]   = 3\n",
    "df.loc[df['EDUCATION'] == 'POST-GRADUATE',['EDUCATION']]    = 4\n",
    "df.loc[df['EDUCATION'] == 'OTHERS',['EDUCATION']]           = 1\n",
    "df.loc[df['EDUCATION'] == 'PROFESSIONAL',['EDUCATION']]     = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36d08587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42064 entries, 0 to 42063\n",
      "Data columns (total 43 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   pct_tl_open_L6M            42064 non-null  float64\n",
      " 1   pct_tl_closed_L6M          42064 non-null  float64\n",
      " 2   Tot_TL_closed_L12M         42064 non-null  int64  \n",
      " 3   pct_tl_closed_L12M         42064 non-null  float64\n",
      " 4   Tot_Missed_Pmnt            42064 non-null  int64  \n",
      " 5   CC_TL                      42064 non-null  int64  \n",
      " 6   Home_TL                    42064 non-null  int64  \n",
      " 7   PL_TL                      42064 non-null  int64  \n",
      " 8   Secured_TL                 42064 non-null  int64  \n",
      " 9   Unsecured_TL               42064 non-null  int64  \n",
      " 10  Other_TL                   42064 non-null  int64  \n",
      " 11  Age_Oldest_TL              42064 non-null  int64  \n",
      " 12  Age_Newest_TL              42064 non-null  int64  \n",
      " 13  time_since_recent_payment  42064 non-null  int64  \n",
      " 14  max_recent_level_of_deliq  42064 non-null  int64  \n",
      " 15  num_deliq_6_12mts          42064 non-null  int64  \n",
      " 16  num_times_60p_dpd          42064 non-null  int64  \n",
      " 17  num_std_12mts              42064 non-null  int64  \n",
      " 18  num_sub                    42064 non-null  int64  \n",
      " 19  num_sub_6mts               42064 non-null  int64  \n",
      " 20  num_sub_12mts              42064 non-null  int64  \n",
      " 21  num_dbt                    42064 non-null  int64  \n",
      " 22  num_dbt_12mts              42064 non-null  int64  \n",
      " 23  num_lss                    42064 non-null  int64  \n",
      " 24  recent_level_of_deliq      42064 non-null  int64  \n",
      " 25  CC_enq_L12m                42064 non-null  int64  \n",
      " 26  PL_enq_L12m                42064 non-null  int64  \n",
      " 27  time_since_recent_enq      42064 non-null  int64  \n",
      " 28  enq_L3m                    42064 non-null  int64  \n",
      " 29  NETMONTHLYINCOME           42064 non-null  int64  \n",
      " 30  Time_With_Curr_Empr        42064 non-null  int64  \n",
      " 31  CC_Flag                    42064 non-null  int64  \n",
      " 32  PL_Flag                    42064 non-null  int64  \n",
      " 33  pct_PL_enq_L6m_of_ever     42064 non-null  float64\n",
      " 34  pct_CC_enq_L6m_of_ever     42064 non-null  float64\n",
      " 35  HL_Flag                    42064 non-null  int64  \n",
      " 36  GL_Flag                    42064 non-null  int64  \n",
      " 37  MARITALSTATUS              42064 non-null  object \n",
      " 38  EDUCATION                  42064 non-null  int64  \n",
      " 39  GENDER                     42064 non-null  object \n",
      " 40  last_prod_enq2             42064 non-null  object \n",
      " 41  first_prod_enq2            42064 non-null  object \n",
      " 42  Approved_Flag              42064 non-null  object \n",
      "dtypes: float64(5), int64(33), object(5)\n",
      "memory usage: 13.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df['EDUCATION'].value_counts()\n",
    "df['EDUCATION'] = df['EDUCATION'].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c114741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42064 entries, 0 to 42063\n",
      "Data columns (total 55 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   pct_tl_open_L6M               42064 non-null  float64\n",
      " 1   pct_tl_closed_L6M             42064 non-null  float64\n",
      " 2   Tot_TL_closed_L12M            42064 non-null  int64  \n",
      " 3   pct_tl_closed_L12M            42064 non-null  float64\n",
      " 4   Tot_Missed_Pmnt               42064 non-null  int64  \n",
      " 5   CC_TL                         42064 non-null  int64  \n",
      " 6   Home_TL                       42064 non-null  int64  \n",
      " 7   PL_TL                         42064 non-null  int64  \n",
      " 8   Secured_TL                    42064 non-null  int64  \n",
      " 9   Unsecured_TL                  42064 non-null  int64  \n",
      " 10  Other_TL                      42064 non-null  int64  \n",
      " 11  Age_Oldest_TL                 42064 non-null  int64  \n",
      " 12  Age_Newest_TL                 42064 non-null  int64  \n",
      " 13  time_since_recent_payment     42064 non-null  int64  \n",
      " 14  max_recent_level_of_deliq     42064 non-null  int64  \n",
      " 15  num_deliq_6_12mts             42064 non-null  int64  \n",
      " 16  num_times_60p_dpd             42064 non-null  int64  \n",
      " 17  num_std_12mts                 42064 non-null  int64  \n",
      " 18  num_sub                       42064 non-null  int64  \n",
      " 19  num_sub_6mts                  42064 non-null  int64  \n",
      " 20  num_sub_12mts                 42064 non-null  int64  \n",
      " 21  num_dbt                       42064 non-null  int64  \n",
      " 22  num_dbt_12mts                 42064 non-null  int64  \n",
      " 23  num_lss                       42064 non-null  int64  \n",
      " 24  recent_level_of_deliq         42064 non-null  int64  \n",
      " 25  CC_enq_L12m                   42064 non-null  int64  \n",
      " 26  PL_enq_L12m                   42064 non-null  int64  \n",
      " 27  time_since_recent_enq         42064 non-null  int64  \n",
      " 28  enq_L3m                       42064 non-null  int64  \n",
      " 29  NETMONTHLYINCOME              42064 non-null  int64  \n",
      " 30  Time_With_Curr_Empr           42064 non-null  int64  \n",
      " 31  CC_Flag                       42064 non-null  int64  \n",
      " 32  PL_Flag                       42064 non-null  int64  \n",
      " 33  pct_PL_enq_L6m_of_ever        42064 non-null  float64\n",
      " 34  pct_CC_enq_L6m_of_ever        42064 non-null  float64\n",
      " 35  HL_Flag                       42064 non-null  int64  \n",
      " 36  GL_Flag                       42064 non-null  int64  \n",
      " 37  EDUCATION                     42064 non-null  int64  \n",
      " 38  Approved_Flag                 42064 non-null  object \n",
      " 39  MARITALSTATUS_Married         42064 non-null  bool   \n",
      " 40  MARITALSTATUS_Single          42064 non-null  bool   \n",
      " 41  GENDER_F                      42064 non-null  bool   \n",
      " 42  GENDER_M                      42064 non-null  bool   \n",
      " 43  last_prod_enq2_AL             42064 non-null  bool   \n",
      " 44  last_prod_enq2_CC             42064 non-null  bool   \n",
      " 45  last_prod_enq2_ConsumerLoan   42064 non-null  bool   \n",
      " 46  last_prod_enq2_HL             42064 non-null  bool   \n",
      " 47  last_prod_enq2_PL             42064 non-null  bool   \n",
      " 48  last_prod_enq2_others         42064 non-null  bool   \n",
      " 49  first_prod_enq2_AL            42064 non-null  bool   \n",
      " 50  first_prod_enq2_CC            42064 non-null  bool   \n",
      " 51  first_prod_enq2_ConsumerLoan  42064 non-null  bool   \n",
      " 52  first_prod_enq2_HL            42064 non-null  bool   \n",
      " 53  first_prod_enq2_PL            42064 non-null  bool   \n",
      " 54  first_prod_enq2_others        42064 non-null  bool   \n",
      "dtypes: bool(16), float64(5), int64(33), object(1)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['MARITALSTATUS','GENDER', 'last_prod_enq2' ,'first_prod_enq2'])\n",
    "\n",
    "df_encoded.info()\n",
    "k = df_encoded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33030a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7636990372043266\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.8370457209847597\n",
      "Recall: 0.7041420118343196\n",
      "F1 Score: 0.7648634172469202\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.7957519116397621\n",
      "Recall: 0.9282457879088206\n",
      "F1 Score: 0.856907593778591\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4423380726698262\n",
      "Recall: 0.21132075471698114\n",
      "F1 Score: 0.28600612870275793\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7178502879078695\n",
      "Recall: 0.7269193391642371\n",
      "F1 Score: 0.7223563495895703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Machine Learing model fitting\n",
    "# Data processing\n",
    "\n",
    "# 1. Random Forest\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 200, random_state=42)\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print ()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c192a9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/20/2f/2ccc91db71096cdb8c5174948db738075d7e38cfece0815500336f6e4ca8/xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /home/kanhaiya/anaconda3/lib/python3.11/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/kanhaiya/anaconda3/lib/python3.11/site-packages (from xgboost) (2.19.3)\n",
      "Requirement already satisfied: scipy in /home/kanhaiya/anaconda3/lib/python3.11/site-packages (from xgboost) (1.11.1)\n",
      "Downloading xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m194.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:34\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.1\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8701d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4)\n",
    "\n",
    "\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56087568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class p1:\n",
      "Precision: 0.823906083244397\n",
      "Recall: 0.7613412228796844\n",
      "F1 Score: 0.7913890312660175\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.8255418233924413\n",
      "Recall: 0.913577799801784\n",
      "F1 Score: 0.8673315769665035\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4756380510440835\n",
      "Recall: 0.30943396226415093\n",
      "F1 Score: 0.37494284407864653\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7342386032977691\n",
      "Recall: 0.7356656948493683\n",
      "F1 Score: 0.7349514563106796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bf8d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.71\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.7272727272727273\n",
      "Recall: 0.7258382642998028\n",
      "F1 Score: 0.7265547877591313\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.8098755832037325\n",
      "Recall: 0.8257680872150645\n",
      "F1 Score: 0.8177446265580528\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.3422924901185771\n",
      "Recall: 0.3267924528301887\n",
      "F1 Score: 0.33436293436293435\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.6481854838709677\n",
      "Recall: 0.6248785228377065\n",
      "F1 Score: 0.636318654131618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=20, min_samples_split=10)\n",
    "dt_model.fit(x_train, y_train)\n",
    "y_pred = dt_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1f1b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "784f2ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
      "Test Accuracy: 0.7811719957209081\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning in xgboost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBClassifier with the initial set of hyperparameters\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "accuracy = best_model.score(x_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38181588",
   "metadata": {},
   "source": [
    "# Based on the Risk Appetite we can suggest  p1,p2,p3,p4 to the business end user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da399cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
